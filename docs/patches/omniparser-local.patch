--- a/util/utils.py
+++ b/util/utils.py
@@ -8,7 +8,10 @@
 import requests
 # utility function
 import os
-from openai import AzureOpenAI
+try:
+    from openai import AzureOpenAI
+except Exception:
+    AzureOpenAI = None
 
 import json
 import sys
@@ -18,17 +21,50 @@
 # %matplotlib inline
 from matplotlib import pyplot as plt
 import easyocr
-from paddleocr import PaddleOCR
-reader = easyocr.Reader(['en'])
-paddle_ocr = PaddleOCR(
-    lang='en',  # other lang also available
-    use_angle_cls=False,
-    use_gpu=False,  # using cuda will conflict with pytorch in the same process
-    show_log=False,
-    max_batch_size=1024,
-    use_dilation=True,  # improves accuracy
-    det_db_score_mode='slow',  # improves accuracy
-    rec_batch_num=1024)
+try:
+    from paddleocr import PaddleOCR
+    _PADDLE_AVAILABLE = True
+    _PADDLE_IMPORT_ERROR = None
+except Exception as exc:
+    PaddleOCR = None
+    _PADDLE_AVAILABLE = False
+    _PADDLE_IMPORT_ERROR = f"{type(exc).__name__}: {exc}"
+
+_easyocr_cache = os.environ.get("EASYOCR_HOME")
+_easyocr_reader = None
+_easyocr_init_error = None
+
+def get_easyocr_reader():
+    global _easyocr_reader, _easyocr_init_error
+    if _easyocr_reader is not None or _easyocr_init_error is not None:
+        return _easyocr_reader
+    try:
+        import torch
+        torch.set_default_dtype(torch.float32)
+        if _easyocr_cache:
+            _easyocr_reader = easyocr.Reader(['en'], gpu=False, model_storage_directory=_easyocr_cache)
+        else:
+            _easyocr_reader = easyocr.Reader(['en'], gpu=False)
+        if hasattr(_easyocr_reader, "detector") and hasattr(_easyocr_reader.detector, "float"):
+            _easyocr_reader.detector = _easyocr_reader.detector.float()
+        if hasattr(_easyocr_reader, "recognizer") and hasattr(_easyocr_reader.recognizer, "float"):
+            _easyocr_reader.recognizer = _easyocr_reader.recognizer.float()
+    except Exception as exc:
+        _easyocr_init_error = f"{type(exc).__name__}: {exc}"
+        _easyocr_reader = None
+    return _easyocr_reader
+paddle_ocr = None
+if _PADDLE_AVAILABLE:
+    try:
+        paddle_ocr = PaddleOCR()
+    except Exception as exc:
+        paddle_ocr = None
+        _PADDLE_AVAILABLE = False
+        _PADDLE_IMPORT_ERROR = f"{type(exc).__name__}: {exc}"
+
+
+def is_paddle_ready() -> bool:
+    return _PADDLE_AVAILABLE and paddle_ocr is not None
 import time
 import base64
 
@@ -224,7 +260,7 @@
                 if not any(IoU(box1, box3) > iou_threshold and not is_inside(box1, box3) for k, box3 in enumerate(ocr_bbox)):
                     filtered_boxes.append(box1)
             else:
-                filtered_boxes.append(box1)
+                filtered_boxes.append({'type': 'icon', 'bbox': box1_elem['bbox'], 'interactivity': True, 'content': None, 'source':'box_yolo_content_yolo'})
     return torch.tensor(filtered_boxes)
 
 
@@ -429,11 +465,13 @@
         ocr_bbox=ocr_bbox.tolist()
     else:
         print('no ocr bbox!!!')
-        ocr_bbox = None
+        ocr_bbox = []
 
     ocr_bbox_elem = [{'type': 'text', 'bbox':box, 'interactivity':False, 'content':txt, 'source': 'box_ocr_content_ocr'} for box, txt in zip(ocr_bbox, ocr_text) if int_box_area(box, w, h) > 0] 
     xyxy_elem = [{'type': 'icon', 'bbox':box, 'interactivity':True, 'content':None} for box in xyxy.tolist() if int_box_area(box, w, h) > 0]
     filtered_boxes = remove_overlap_new(boxes=xyxy_elem, iou_threshold=iou_threshold, ocr_bbox=ocr_bbox_elem)
+    if filtered_boxes and not isinstance(filtered_boxes[0], dict):
+        filtered_boxes = [{'type': 'icon', 'bbox': box, 'interactivity': True, 'content': None, 'source': 'box_yolo_content_yolo'} for box in filtered_boxes]
     
     # sort the filtered_boxes so that the one with 'content': None is at the end, and get the index of the first 'content': None
     filtered_boxes_elem = sorted(filtered_boxes, key=lambda x: x['content'] is None)
@@ -509,17 +547,56 @@
         image_source = image_source.convert('RGB')
     image_np = np.array(image_source)
     w, h = image_source.size
+    if use_paddleocr and (not _PADDLE_AVAILABLE or paddle_ocr is None):
+        print("PaddleOCR unavailable, falling back to EasyOCR:", _PADDLE_IMPORT_ERROR)
+        use_paddleocr = False
     if use_paddleocr:
         if easyocr_args is None:
             text_threshold = 0.5
         else:
             text_threshold = easyocr_args['text_threshold']
-        result = paddle_ocr.ocr(image_np, cls=False)[0]
-        coord = [item[0] for item in result if item[1][1] > text_threshold]
-        text = [item[1][0] for item in result if item[1][1] > text_threshold]
-    else:  # EasyOCR
+        try:
+            raw_result = paddle_ocr.ocr(image_np)
+        except Exception as exc:
+            print("PaddleOCR failed, falling back to EasyOCR:", exc)
+            use_paddleocr = False
+            raw_result = None
+        if use_paddleocr:
+            if isinstance(raw_result, list) and len(raw_result) == 1 and isinstance(raw_result[0], list):
+                result = raw_result[0]
+            else:
+                result = raw_result
+            coord = []
+            text = []
+            if result is None:
+                result = []
+            for item in result:
+                box = None
+                txt = None
+                score = None
+                if isinstance(item, dict):
+                    box = item.get("points") or item.get("bbox") or item.get("box")
+                    txt = item.get("text") or item.get("rec_text") or item.get("transcription")
+                    score = item.get("score") or item.get("confidence") or item.get("rec_score")
+                elif isinstance(item, (list, tuple)) and len(item) >= 2:
+                    box = item[0]
+                    if isinstance(item[1], (list, tuple)):
+                        txt = item[1][0] if len(item[1]) > 0 else None
+                        score = item[1][1] if len(item[1]) > 1 else None
+                    else:
+                        txt = item[1]
+                if box is None or txt is None:
+                    continue
+                if score is None or score > text_threshold:
+                    coord.append(box)
+                    text.append(txt)
+    if not use_paddleocr:  # EasyOCR
         if easyocr_args is None:
             easyocr_args = {}
+        reader = get_easyocr_reader()
+        if reader is None:
+            print("EasyOCR unavailable, returning empty OCR results:", _easyocr_init_error)
+            return ([], []), goal_filtering
         result = reader.readtext(image_np, **easyocr_args)
         coord = [item[0] for item in result]
         text = [item[1] for item in result]
@@ -537,4 +614,4 @@
             bb = [get_xywh(item) for item in coord]
         elif output_bb_format == 'xyxy':
             bb = [get_xyxy(item) for item in coord]
-    return (text, bb), goal_filtering
\ No newline at end of file
+    return (text, bb), goal_filtering
--- a/util/omniparser.py
+++ b/util/omniparser.py
@@ -1,4 +1,4 @@
-from util.utils import get_som_labeled_img, get_caption_model_processor, get_yolo_model, check_ocr_box
+from util.utils import get_som_labeled_img, get_caption_model_processor, get_yolo_model, check_ocr_box, is_paddle_ready
 import torch
 from PIL import Image
 import io
@@ -10,7 +10,17 @@
         device = 'cuda' if torch.cuda.is_available() else 'cpu'
 
         self.som_model = get_yolo_model(model_path=config['som_model_path'])
-        self.caption_model_processor = get_caption_model_processor(model_name=config['caption_model_name'], model_name_or_path=config['caption_model_path'], device=device)
+        self.use_local_semantics = True
+        try:
+            self.caption_model_processor = get_caption_model_processor(
+                model_name=config['caption_model_name'],
+                model_name_or_path=config['caption_model_path'],
+                device=device,
+            )
+        except Exception as exc:
+            self.caption_model_processor = None
+            self.use_local_semantics = False
+            print("Caption model load failed, fallback to no local semantics:", exc)
         print('Omniparser initialized!!!')
 
     def parse(self, image_base64: str):
@@ -26,7 +36,26 @@
             'thickness': max(int(3 * box_overlay_ratio), 1),
         }
 
-        (text, ocr_bbox), _ = check_ocr_box(image, display_img=False, output_bb_format='xyxy', easyocr_args={'text_threshold': 0.8}, use_paddleocr=False)
-        dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(image, self.som_model, BOX_TRESHOLD = self.config['BOX_TRESHOLD'], output_coord_in_ratio=True, ocr_bbox=ocr_bbox,draw_bbox_config=draw_bbox_config, caption_model_processor=self.caption_model_processor, ocr_text=text,use_local_semantics=True, iou_threshold=0.7, scale_img=False, batch_size=128)
+        (text, ocr_bbox), _ = check_ocr_box(
+            image,
+            display_img=False,
+            output_bb_format='xyxy',
+            easyocr_args={'text_threshold': 0.8},
+            use_paddleocr=is_paddle_ready()
+        )
+        dino_labled_img, label_coordinates, parsed_content_list = get_som_labeled_img(
+            image,
+            self.som_model,
+            BOX_TRESHOLD=self.config['BOX_TRESHOLD'],
+            output_coord_in_ratio=True,
+            ocr_bbox=ocr_bbox,
+            draw_bbox_config=draw_bbox_config,
+            caption_model_processor=self.caption_model_processor,
+            ocr_text=text,
+            use_local_semantics=self.use_local_semantics,
+            iou_threshold=0.7,
+            scale_img=False,
+            batch_size=128,
+        )
 
-        return dino_labled_img, parsed_content_list
\ No newline at end of file
+        return dino_labled_img, parsed_content_list
